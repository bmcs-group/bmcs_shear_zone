{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee944b8-be00-4813-b4b4-4d46146718f3",
   "metadata": {},
   "source": [
    "# Preliminary steps\n",
    "\n",
    "Transform the csv files into a zipped npy format with a reduced size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb407ee-caeb-40c7-9fab-621cf5039341",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265582e-74db-456c-980c-02ab68ab5db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a6ba5-36f2-4773-b3bd-b7b610025e62",
   "metadata": {},
   "source": [
    "### Time-steps and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118a5e4-bf28-46a4-ad30-12dd0a61eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = op.expanduser('~')\n",
    "base_dir = op.join(home_dir, 'simdb', 'data', 'asinning')\n",
    "data_dir_name = '3D-Aramis'\n",
    "time_F_dic_file_name = 'S16-1_Kraft.csv'\n",
    "data_path = op.join(base_dir, 'S16')\n",
    "csv_data_dir = op.join(data_path, data_dir_name)\n",
    "time_F_dic_file = op.join(data_path, time_F_dic_file_name)\n",
    "npz_file = op.join(data_path, 'S16.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6020a6a-d462-44e1-b153-291d7909ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71338f02-793b-4e14-b4aa-22ade57e5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_F_dic_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c5b741-43cb-4d68-ae50-3e0486627df6",
   "metadata": {},
   "source": [
    "## Read the load deflection curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cb097-0f2b-4d59-9ec6-aab059b2a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_F_w_m = np.array(\n",
    "    pd.read_csv(time_F_dic_file, decimal=\",\", skiprows=1,\n",
    "    delimiter=';'), dtype=np.float_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ef73b-3603-4f6c-a204-2093da49857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pxyze_file_T = [op.join(csv_data_dir, dic_file) for dic_file in os.listdir(csv_data_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00236165-920f-4121-b310-d70e3ec000f8",
   "metadata": {},
   "source": [
    "## Read from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb3457-f99a-47a9-bfec-5205a76f05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pxyze_file_T[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94ca54-604e-4e71-88e5-2bcc30fe36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pxyze_list = [\n",
    "    np.loadtxt(pxyz_file, dtype=np.float_,\n",
    "               skiprows=6, delimiter=';', usecols=(0, 1, 2, 3, 4))\n",
    "    for pxyz_file in pxyze_file_T\n",
    "]\n",
    "n_T = len(pxyze_list)\n",
    "n_T -= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f77de7-0b39-4282-ba69-b156fddd4b3d",
   "metadata": {},
   "source": [
    "## Do all the data records for each time step have the same length?\n",
    "\n",
    "Since some points were lost during the cracking, not all records are the same.\n",
    "The next code identifies all points that exist in all time steps and ignores those points\n",
    "that were lost during the cracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095b9f0e-1fb3-4d49-956e-cd378bb978fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all point ids in all time steps\n",
    "P_list = [np.array(pxyz[:, 0], dtype=np.int_)\n",
    "          for pxyz in pxyze_list[:n_T]]\n",
    "# Maximum number of points ocurring in one of the time steps to allocate the space\n",
    "max_n_P = np.max(np.array([np.max(P_) for P_ in P_list])) + 1\n",
    "# Only points occurring in all time steps are considered\n",
    "P_Q = P_list[0]\n",
    "for P_next in P_list[1:]:\n",
    "    P_Q = np.intersect1d(P_Q, P_next)\n",
    "# Define the initial configuration\n",
    "X_TPa = np.zeros((n_T, max_n_P, 3), dtype=np.float_)\n",
    "for T in range(n_T):\n",
    "    X_TPa[T, P_list[T]] = pxyze_list[T][:, 1:4]\n",
    "X_TQa = X_TPa[:, P_Q, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c3d6f-5b7d-4903-aa96-3ae0dcaf0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0Qa = X_TQa[0]\n",
    "U_TQa =  X_TQa - X_0Qa[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a801d3ae-643c-4488-9f12-a64fa6529a4e",
   "metadata": {},
   "source": [
    "## Compressed array data files `npz` and `npy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e896247-17dd-4dfe-9bb2-9f524c23b32b",
   "metadata": {},
   "source": [
    "Write the compressed numpy file containing several arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d331c-6953-4ea3-8a77-82fcaf014c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('S16.npz', X_0Qa=X_0Qa, U_TQa=U_TQa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14887a90-e56e-4a56-b380-4e9c58bbd123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33854162-9023-4378-ab2f-09c2fe112cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmcs_env2",
   "language": "python",
   "name": "bmcs_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
